{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# claim_data_path = \"./data/patent/kipris_claim_patent.csv\"\n",
    "# claim_df = pd.read_csv(claim_data_path)\n",
    "# claim_df = claim_df.drop(columns=[\"Unnamed: 0\"])\n",
    "# claim_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. mecab-ko-dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6663692,\n",
       "     실시예  Unnamed: 1  Unnamed: 2  Unnamed: 3  NNG  *  F 실시예.1 *.1 *.2 *.3 *.4\n",
       " 0    일측         NaN         NaN         NaN  NNG  *  T    일측   *   *   *   *\n",
       " 1   청구항         NaN         NaN         NaN  NNG  *  T   청구항   *   *   *   *\n",
       " 2   제어부         NaN         NaN         NaN  NNG  *  F   제어부   *   *   *   *\n",
       " 3  어드레스         NaN         NaN         NaN  NNG  *  F  어드레스   *   *   *   *\n",
       " 4  제조방법         NaN         NaN         NaN  NNG  *  T  제조방법   *   *   *   *)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = \"/home/ui/project/graduate_paper/korpatElectra/KIPI-KorPatELECTRA/pat_all_mecab_dic.csv\"\n",
    "# user_dict = pd.read_csv(path)\n",
    "# len(user_dict), user_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'본 고안 은 주로 일회용 합성세제액 을 집어넣 어 밀봉 하 는 세제액포 의 내부 를 원호 상 으로 열중 착하 되 세제액 이 배출 되 는 절단부 쪽 으로 내벽 을 협소 하 게 형성 하 여서 내부 에 들 어 있 는 세제액 을 잘 짜 질 수 있 도록 하 는 합성세제 액포 에 관한 것 이 다 .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "\n",
    "sentence_org = \"본 고안은 주로 일회용 합성세제액을 집어넣어 밀봉하는 세제액포의 내부를 원호상으로 열중착하되 세제액이 배출되는 절단부 쪽으로 내벽을 협소하게 형성하여서 내부에 들어있는 세제액을 잘짜질 수 있도록 하는 합성세제 액포에 관한 것이다.\"\n",
    "m = Mecab()\n",
    "sentence_kipi = \" \".join(m.morphs(sentence_org))\n",
    "sentence_kipi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 토크나이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "# 정확한 tokenizer.py 경로 지정\n",
    "tokenizer_path = \"./korpatElectra/KIPI-KorPatELECTRA/tokenizer.py\"\n",
    "\n",
    "# 모듈 불러오기\n",
    "spec = importlib.util.spec_from_file_location(\"custom_tokenizer\", tokenizer_path)\n",
    "tokenization = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(tokenization)\n",
    "\n",
    "# FullTokenizer 테스트\n",
    "tokenizer = tokenization.FullTokenizer(vocab_file=\"./korpatElectra/KIPI-KorPatELECTRA/vocab.txt\", do_lower_case=False)\n",
    "tokenizer_vocab = tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of vocab :  35000\n",
      "Input example :  본 고안은 주로 일회용 합성세제액을 집어넣어 밀봉하는 세제액포의 내부를 원호상으로 열중착하되 세제액이 배출되는 절단부 쪽으로 내벽을 협소하게 형성하여서 내부에 들어있는 세제액을 잘짜질 수 있도록 하는 합성세제 액포에 관한 것이다.\n",
      "Tokenized example :  ['본', '고안', '은', '주로', '일회용', '합성', '##세제', '##액', '을', '집어넣', '어', '밀봉', '하', '는', '세제', '##액', '##포', '의', '내부', '를', '원호', '상', '으로', '열', '##중', '착하', '되', '세제', '##액', '이', '배출', '되', '는', '절단부', '쪽', '으로', '내벽', '을', '협소', '하', '게', '형성', '하', '여서', '내부', '에', '들', '어', '있', '는', '세제', '##액', '을', '잘', '짜', '질', '수', '있', '도록', '하', '는', '합성', '##세제', '액', '##포', '에', '관한', '것', '이', '다', '.']\n",
      "Encoded line :  [1100, 5050, 1674, 6748, 10190, 5147, 27099, 2750, 1675, 28837, 1535, 5795, 2381, 519, 9646, 2750, 2940, 1687, 4771, 881, 9523, 1251, 4682, 1565, 2591, 20032, 618, 9646, 2750, 1692, 4977, 618, 519, 13247, 1886, 4682, 7485, 1675, 14947, 2381, 155, 4689, 2381, 7926, 4771, 1553, 657, 1535, 1703, 519, 9646, 2750, 1675, 1712, 1849, 1840, 1351, 1703, 4692, 2381, 519, 5147, 27099, 1512, 2940, 1553, 4845, 148, 1692, 542, 8]\n",
      "Decoded line :  ['본', '고안', '은', '주로', '일회용', '합성', '##세제', '##액', '을', '집어넣', '어', '밀봉', '하', '는', '세제', '##액', '##포', '의', '내부', '를', '원호', '상', '으로', '열', '##중', '착하', '되', '세제', '##액', '이', '배출', '되', '는', '절단부', '쪽', '으로', '내벽', '을', '협소', '하', '게', '형성', '하', '여서', '내부', '에', '들', '어', '있', '는', '세제', '##액', '을', '잘', '짜', '질', '수', '있', '도록', '하', '는', '합성', '##세제', '액', '##포', '에', '관한', '것', '이', '다', '.']\n"
     ]
    }
   ],
   "source": [
    "# 사용자 사전이 추가된 mecab-ko 형태소 분리기로 1차 분리\n",
    "m = Mecab()\n",
    "sentence_kipi = \" \".join(m.morphs(sentence_org))\n",
    "\n",
    "# 2차 분리\n",
    "tokens = tokenizer.tokenize(sentence_kipi)\n",
    "encoded_line = tokenizer.convert_tokens_to_ids(tokens)\n",
    "decoded_line = tokenizer.convert_ids_to_tokens(encoded_line)\n",
    "print(\"Length of vocab : \", len(tokenizer_vocab))\n",
    "print(\"Input example : \", sentence_org)\n",
    "print(\"Tokenized example : \", tokens)\n",
    "print(\"Encoded line : \", encoded_line)\n",
    "print(\"Decoded line : \", decoded_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
